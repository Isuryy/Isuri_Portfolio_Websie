{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auuaEk9iaMyg"
      },
      "source": [
        "Copyright (c) Meta Platforms, Inc. and affiliates. All rights reserved. This source code is licensed under the license found in the LICENSE file in the root directory of this source tree.\n",
        "\n",
        "# Video Seal Inference\n",
        "\n",
        "[[`arXiv`](https://arxiv.org/abs/2412.09492)]\n",
        "[[`Colab`](https://colab.research.google.com/github/facebookresearch/videoseal/blob/main/notebooks/colab.ipynb)]\n",
        "[[`Demo`](https://aidemos.meta.com/videoseal)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoYZTunqvkXw"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktbpIy3maMyi"
      },
      "source": [
        "Clone repository and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXXEkRqEaMyi",
        "outputId": "780529bb-9cc8-4d13-86a1-06408a0b7f77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'videoseal'...\n",
            "remote: Enumerating objects: 6027, done.\u001b[K\n",
            "remote: Counting objects: 100% (160/160), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 6027 (delta 110), reused 84 (delta 81), pack-reused 5867 (from 3)\u001b[K\n",
            "Receiving objects: 100% (6027/6027), 210.92 MiB | 20.25 MiB/s, done.\n",
            "Resolving deltas: 100% (4105/4105), done.\n",
            "/content/videoseal\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/videoseal.git\n",
        "%cd videoseal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7HepUuOaMyj"
      },
      "source": [
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmrcsfF8aMyj",
        "outputId": "f7b119bb-4164-4179-ec0e-b7cd0faadbb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (4.12.0.88)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.8.1)\n",
            "Collecting lpips (from -r requirements.txt (line 5))\n",
            "  Downloading lpips-0.1.4-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting timm==0.9.16 (from -r requirements.txt (line 6))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting pre-commit (from -r requirements.txt (line 7))\n",
            "  Downloading pre_commit-4.5.1-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (6.17.1)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.10)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Collecting pytorch_msssim (from -r requirements.txt (line 15))\n",
            "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (2.19.0)\n",
            "Collecting calflops (from -r requirements.txt (line 17))\n",
            "  Downloading calflops-0.3.2-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 18)) (4.57.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (0.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 24)) (1.16.3)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 25))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting av (from -r requirements.txt (line 26))\n",
            "  Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (2.9.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.24.0+cpu)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm==0.9.16->-r requirements.txt (line 6)) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.3)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf->-r requirements.txt (line 3)) (4.9.3)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit->-r requirements.txt (line 7))\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit->-r requirements.txt (line 7))\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit->-r requirements.txt (line 7))\n",
            "  Downloading nodeenv-1.10.0-py2.py3-none-any.whl.metadata (24 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit->-r requirements.txt (line 7))\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 8)) (5.7.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 12)) (3.6.1)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 12)) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 12)) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 12)) (2025.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->-r requirements.txt (line 12)) (0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.10)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard->-r requirements.txt (line 16)) (3.1.4)\n",
            "Requirement already satisfied: accelerate>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from calflops->-r requirements.txt (line 17)) (1.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 18)) (3.20.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 18)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 18)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 18)) (0.22.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from ffmpeg-python->-r requirements.txt (line 25)) (1.0.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard->-r requirements.txt (line 16)) (4.15.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm==0.9.16->-r requirements.txt (line 6)) (1.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8))\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 8)) (5.9.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm==0.9.16->-r requirements.txt (line 6)) (3.1.6)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7))\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 7)) (4.5.1)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 16)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 18)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 18)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 18)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->-r requirements.txt (line 18)) (2025.11.12)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.8.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 8)) (0.2.14)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm==0.9.16->-r requirements.txt (line 6)) (1.3.0)\n",
            "Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lpips-0.1.4-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.1-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
            "Downloading calflops-0.3.2-py3-none-any.whl (29 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading av-16.0.1-cp312-cp312-manylinux_2_28_x86_64.whl (40.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.10.0-py2.py3-none-any.whl (23 kB)\n",
            "Downloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distlib, virtualenv, nodeenv, jedi, identify, ffmpeg-python, cfgv, av, pre-commit, pytorch_msssim, timm, lpips, calflops\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.22\n",
            "    Uninstalling timm-1.0.22:\n",
            "      Successfully uninstalled timm-1.0.22\n",
            "Successfully installed av-16.0.1 calflops-0.3.2 cfgv-3.5.0 distlib-0.4.0 ffmpeg-python-0.2.0 identify-2.6.15 jedi-0.19.2 lpips-0.1.4 nodeenv-1.10.0 pre-commit-4.5.1 pytorch_msssim-1.0.0 timm-0.9.16 virtualenv-20.35.4\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q16r0X1CaMyk"
      },
      "source": [
        "## Imports and loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPfZw_FAaMyk",
        "outputId": "eae17ad8-d1f1-4b91-b1bd-37f1fc0732cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/videoseal\n"
          ]
        }
      ],
      "source": [
        "%cd /content/videoseal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZIicYPSXaMyl",
        "outputId": "7573d626-6dd5-4f79-cba2-580b3ee564ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/videoseal/videoseal/models/baselines.py:339: SyntaxWarning: invalid escape sequence '\\;'\n",
            "  `pip install huggingface_hub; huggingface-cli download tangtianzhong/img-wm-torchscript --cache-dir .cache; mkdir ckpts; find .cache/models--tangtianzhong--img-wm-torchscript/snapshots/845dc751783db2a03a4b14ea600b0a4a9aba89aa -type l -exec cp --dereference {} ckpts/ \\; sleep 5 ;rm -rf .cache`\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import logging\n",
        "logging.getLogger(\"matplotlib.image\").setLevel(logging.ERROR)\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import ffmpeg\n",
        "import os\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "import torch\n",
        "\n",
        "from videoseal.evals.metrics import bit_accuracy\n",
        "from videoseal.models import Videoseal\n",
        "from videoseal.utils.cfg import setup_model_from_model_card\n",
        "\n",
        "\n",
        "def get_video_info(input_path):\n",
        "    # Open the video file\n",
        "    video = cv2.VideoCapture(input_path)\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = video.get(cv2.CAP_PROP_FPS)\n",
        "    codec = int(video.get(cv2.CAP_PROP_FOURCC))\n",
        "    num_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Decode codec to human-readable form\n",
        "    codec_str = \"\".join([chr((codec >> 8 * i) & 0xFF) for i in range(4)])\n",
        "\n",
        "    video.release()  # Close the video file\n",
        "\n",
        "    return {\n",
        "        \"width\": width,\n",
        "        \"height\": height,\n",
        "        \"fps\": fps,\n",
        "        \"codec\": codec_str,\n",
        "        \"num_frames\": num_frames\n",
        "    }\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tGZxcKuaMyl"
      },
      "source": [
        "## Load the model\n",
        "\n",
        "The videoseal library provides pretrained models for embedding and extracting watermarks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_8BMj5UaMym",
        "outputId": "7911859c-54a5-4489-b8eb-43a5ad073811"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File https://dl.fbaipublicfiles.com/videoseal/y_256b_img.pth downloaded successfully to /content/videoseal/ckpts/videoseal_y_256b_img.pth\n",
            "Model loaded successfully from /content/videoseal/ckpts/videoseal_y_256b_img.pth with message: <All keys matched successfully>\n"
          ]
        }
      ],
      "source": [
        "# Load the VideoSeal model\n",
        "model = setup_model_from_model_card(\"videoseal\")\n",
        "\n",
        "# Set the model to evaluation mode and move it to the selected device\n",
        "model = model.eval()\n",
        "model = model.to(device)\n",
        "model.compile()\n",
        "\n",
        "# Setup the step size. Bigger step size makes embedding faster but loses a bit of robustness.\n",
        "model.step_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDB8D9e6aMym"
      },
      "source": [
        "## Embedding\n",
        "\n",
        "The embedding process is the process of hiding the watermark in the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeT-7WzXaMym"
      },
      "outputs": [],
      "source": [
        "def embed_video_clip(\n",
        "    model: Videoseal,\n",
        "    clip: np.ndarray,\n",
        "    msgs: torch.Tensor\n",
        ") -> np.ndarray:\n",
        "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "    outputs = model.embed(clip_tensor, msgs=msgs, is_video=True, lowres_attenuation=True)\n",
        "    processed_clip = outputs[\"imgs_w\"]\n",
        "    processed_clip = (processed_clip * 255.0).byte().permute(0, 2, 3, 1).numpy()\n",
        "    return processed_clip\n",
        "\n",
        "def embed_video(\n",
        "    model: Videoseal,\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    chunk_size: int,\n",
        "    crf: int = 23\n",
        ") -> None:\n",
        "    # Read video dimensions\n",
        "    video_info = get_video_info(input_path)\n",
        "    width = int(video_info['width'])\n",
        "    height = int(video_info['height'])\n",
        "    fps = float(video_info['fps'])\n",
        "    codec = video_info['codec']\n",
        "    num_frames = int(video_info['num_frames'])\n",
        "\n",
        "    # Open the input video\n",
        "    process1 = (\n",
        "        ffmpeg\n",
        "        .input(input_path)\n",
        "        .output('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
        "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "    # Open the output video\n",
        "    process2 = (\n",
        "        ffmpeg\n",
        "        .input('pipe:', format='rawvideo', pix_fmt='rgb24', s='{}x{}'.format(width, height), r=fps)\n",
        "        .output(output_path, vcodec='libx264', pix_fmt='yuv420p', r=fps, crf=crf)\n",
        "        .overwrite_output()\n",
        "        .run_async(pipe_stdin=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "\n",
        "    # Create a random message\n",
        "    msgs = model.get_random_msg()\n",
        "    with open(output_path.replace(\".mp4\", \".txt\"), \"w\") as f:\n",
        "        f.write(\"\".join([str(msg.item()) for msg in msgs[0]]))\n",
        "\n",
        "    # Process the video\n",
        "    frame_size = width * height * 3\n",
        "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
        "    frame_count = 0\n",
        "    pbar = tqdm(total=num_frames, desc=\"Watermark embedding\")\n",
        "    while True:\n",
        "        in_bytes = process1.stdout.read(frame_size)\n",
        "        if not in_bytes:\n",
        "            break\n",
        "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
        "        chunk[frame_count % chunk_size] = frame\n",
        "        frame_count += 1\n",
        "        pbar.update(1)\n",
        "        if frame_count % chunk_size == 0:\n",
        "            processed_frame = embed_video_clip(model, chunk, msgs)\n",
        "            process2.stdin.write(processed_frame.tobytes())\n",
        "    process1.stdout.close()\n",
        "    process2.stdin.close()\n",
        "    process1.wait()\n",
        "    process2.wait()\n",
        "\n",
        "    return msgs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKOJP7GTa1xO"
      },
      "source": [
        "You are free to upload any video and change the `video_path`.\n",
        "\n",
        "You can look at the watermark video output in the folder `outputs`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XX1TKDega1Wg"
      },
      "outputs": [],
      "source": [
        "# Path to the input video\n",
        "video_path = \"./assets/videos/1.mp4\"\n",
        "\n",
        "# Create the output directory and path\n",
        "output_dir = \"./outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, os.path.basename(video_path))\n",
        "\n",
        "# Embed the watermark inside the video with a random msg\n",
        "msgs_ori = embed_video(model, video_path, output_path, 16)\n",
        "print(f\"\\nSaved watermarked video to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJPpKOMDaMym"
      },
      "source": [
        "## Extraction\n",
        "\n",
        "Load the video output from the embedding process and extract the watermark."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJxWT4F6aMym"
      },
      "outputs": [],
      "source": [
        "def detect_video_clip(\n",
        "    model: Videoseal,\n",
        "    clip: np.ndarray\n",
        ") -> torch.Tensor:\n",
        "    clip_tensor = torch.tensor(clip, dtype=torch.float32).permute(0, 3, 1, 2) / 255.0\n",
        "    outputs = model.detect(clip_tensor, is_video=True)\n",
        "    output_bits = outputs[\"preds\"][:, 1:]  # exclude the first which may be used for detection\n",
        "    return output_bits\n",
        "\n",
        "def detect_video(\n",
        "    model: Videoseal,\n",
        "    input_path: str,\n",
        "    num_frames_for_extraction: int,\n",
        "    chunk_size: int\n",
        ") -> None:\n",
        "    # Read video dimensions\n",
        "    video_info = get_video_info(input_path)\n",
        "    width = int(video_info['width'])\n",
        "    height = int(video_info['height'])\n",
        "    num_frames = int(video_info['num_frames'])\n",
        "\n",
        "    # Open the input video\n",
        "    process1 = (\n",
        "        ffmpeg\n",
        "        .input(input_path)\n",
        "        .output('pipe:', format='rawvideo', pix_fmt='rgb24')\n",
        "        .run_async(pipe_stdout=True, pipe_stderr=subprocess.PIPE)\n",
        "    )\n",
        "\n",
        "    # Process the video\n",
        "    frame_size = width * height * 3\n",
        "    chunk = np.zeros((chunk_size, height, width, 3), dtype=np.uint8)\n",
        "    frame_count = 0\n",
        "    soft_msgs = []\n",
        "    pbar = tqdm(total=num_frames, desc=\"Watermark extraction\")\n",
        "    while True:\n",
        "        if frame_count >= num_frames_for_extraction:\n",
        "            break\n",
        "        in_bytes = process1.stdout.read(frame_size)\n",
        "        if not in_bytes:\n",
        "            break\n",
        "        frame = np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3])\n",
        "        chunk[frame_count % chunk_size] = frame\n",
        "        frame_count += 1\n",
        "        pbar.update(1)\n",
        "        if frame_count % chunk_size == 0:\n",
        "            soft_msgs.append(detect_video_clip(model, chunk))\n",
        "    process1.stdout.close()\n",
        "    process1.wait()\n",
        "\n",
        "    soft_msgs = torch.cat(soft_msgs, dim=0)\n",
        "    soft_msgs = soft_msgs.mean(dim=0)  # Average the predictions across all frames\n",
        "    return soft_msgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNiST7E8vkYC"
      },
      "outputs": [],
      "source": [
        "# Detect the watermark\n",
        "num_frames_for_extraction = 32\n",
        "soft_msgs = detect_video(model, output_path, num_frames_for_extraction, 16)\n",
        "bit_acc = bit_accuracy(soft_msgs, msgs_ori).item() * 100\n",
        "print(f\"\\nBinary message extracted with {bit_acc:.1f}% bit accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSzD8NV7vkYD"
      },
      "source": [
        "## Run other baselines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gun_lqjfvkYD"
      },
      "source": [
        "To download other checkpoints, you can run the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsDX_uGqcP5d"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub\n",
        "!huggingface-cli download tangtianzhong/img-wm-torchscript --cache-dir .cache\n",
        "!mkdir ckpts\n",
        "!cp .cache/models--tangtianzhong--img-wm-torchscript/snapshots/845dc751783db2a03a4b14ea600b0a4a9aba89aa/*.pt ckpts/\n",
        "!rm -rf .cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QO6-OyrpvkYF"
      },
      "outputs": [],
      "source": [
        "from videoseal.utils.cfg import setup_model_from_checkpoint\n",
        "\n",
        "model = setup_model_from_checkpoint(\"baseline/trustmark\")\n",
        "model = model.eval()\n",
        "model = model.to(device)\n",
        "model.compile()\n",
        "\n",
        "model.chunk_size = 32  # embed 32 frames/imgs at a time\n",
        "model.step_size = 4  # propagate the wm to 4 next frame/img\n",
        "# model.blender.scaling_w *= 1.5  # imperceptibility/robustness trade-off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ixuO00vkYG"
      },
      "source": [
        "### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUVdWr3yvkYG"
      },
      "outputs": [],
      "source": [
        "# Path to the input video\n",
        "video_path = \"./assets/videos/1.mp4\"\n",
        "\n",
        "# Create the output directory and path\n",
        "output_dir = \"./outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "output_path = os.path.join(output_dir, os.path.basename(video_path))\n",
        "\n",
        "# Embed the watermark inside the video with a random msg\n",
        "msgs_ori = embed_video(model, video_path, output_path, 16)\n",
        "print(f\"\\nSaved watermarked video to {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdOFQjGDvkYH"
      },
      "source": [
        "### Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4tRNvaVvkYH"
      },
      "outputs": [],
      "source": [
        "# Detect the watermark\n",
        "num_frames_for_extraction = 32\n",
        "soft_msgs = detect_video(model, output_path, num_frames_for_extraction, 16)\n",
        "bit_acc = bit_accuracy(soft_msgs, msgs_ori).item() * 100\n",
        "print(f\"\\nBinary message extracted with {bit_acc:.1f}% bit accuracy\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}